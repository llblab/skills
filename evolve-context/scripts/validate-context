#!/bin/bash

# Context Evolution Protocol Validator
# Multi-index, bloat-aware validation for project documentation health

set -euo pipefail

# Trap unexpected errors with context
trap 'echo "RUNTIME ERROR: validate-context crashed at line $LINENO (exit code $?)" >&2' ERR

# Force a UTF-8 locale for deterministic anchor normalization with Unicode headings.
# Fall back to plain C locale when UTF-8 variants are unavailable.
if locale -a 2>/dev/null | grep -qiE '^en_US\.(UTF-8|utf8)$'; then
    export LC_ALL="en_US.UTF-8"
    export LANG="en_US.UTF-8"
elif locale -a 2>/dev/null | grep -qiE '^C\.(UTF-8|utf8)$'; then
    export LC_ALL="C.UTF-8"
    export LANG="C.UTF-8"
else
    export LC_ALL="C"
    export LANG="C"
fi

# Colors
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
RED='\033[0;31m'
CYAN='\033[0;36m'
NC='\033[0m'

# Configuration
PROJECT_ROOT="${VALIDATE_CONTEXT_ROOT:-$(pwd)}"
OUTPUT_JSON=false
[[ "${1:-}" == "--json" ]] && OUTPUT_JSON=true
INDEX_CANDIDATES=("AGENTS.md" "CLAUDE.md" "CODEX.md" "GEMINI.md" "CONTEXT.md")

ERRORS=0
WARNINGS=0

# JSON collection
JSON_ITEMS=()
json_add() {
    local level=$1 msg=$2
    # Escape quotes for JSON
    msg="${msg//\\/\\\\}"
    msg="${msg//\"/\\\"}"
    JSON_ITEMS+=("{\"level\":\"$level\",\"message\":\"$msg\"}")
}

# Logging
log_pass() {
    if [[ "$OUTPUT_JSON" == "false" ]]; then
        echo -e "${GREEN}[PASS]${NC} $1"
    fi
    json_add "pass" "$1"
}
log_warn() {
    WARNINGS=$((WARNINGS + 1))
    if [[ "$OUTPUT_JSON" == "false" ]]; then
        echo -e "${YELLOW}[WARN]${NC} $1"
    fi
    json_add "warn" "$1"
}
log_fail() {
    ERRORS=$((ERRORS + 1))
    if [[ "$OUTPUT_JSON" == "false" ]]; then
        echo -e "${RED}[FAIL]${NC} $1"
    fi
    json_add "fail" "$1"
}
log_info() {
    if [[ "$OUTPUT_JSON" == "false" ]]; then
        echo -e "${CYAN}[INFO]${NC} $1"
    fi
    json_add "info" "$1"
}

echo_progress() {
    [[ "$OUTPUT_JSON" == "false" ]] && echo "$@" || true
}

echo_progress "<CONTEXT EVOLUTION PROTOCOL BASED VALIDATOR>"

# --- Check 1: Index file detection (AGENTS.md | CLAUDE.md | CONTEXT.md) ---
CONTEXT_FILE=""
CONTEXT_NAME=""
for candidate in "${INDEX_CANDIDATES[@]}"; do
    if [[ -f "$PROJECT_ROOT/$candidate" ]]; then
        CONTEXT_FILE="$PROJECT_ROOT/$candidate"
        CONTEXT_NAME="$candidate"
        break
    fi
done

if [[ -n "$CONTEXT_FILE" ]]; then
    log_pass "Index file detected: $CONTEXT_NAME"
else
    log_fail "No index file found (checked: ${INDEX_CANDIDATES[*]})"
fi

# --- Check 1b: Root README connectivity ---
README_FILE="$PROJECT_ROOT/README.md"
if [[ -f "$README_FILE" ]]; then
    if grep -q "docs/README.md" "$README_FILE" 2>/dev/null; then
        log_pass "README links to docs/README.md"
    else
        log_warn "README missing link to docs/README.md"
    fi

    if [[ -n "$CONTEXT_NAME" ]] && grep -q "$CONTEXT_NAME" "$README_FILE" 2>/dev/null; then
        log_pass "README references index file ($CONTEXT_NAME)"
    else
        log_warn "README missing reference to index file ($CONTEXT_NAME)"
    fi
else
    log_warn "README.md missing"
fi

# --- Check 2: Core structure ---
if [[ -n "$CONTEXT_FILE" ]]; then
    # Accept either numbered sections (## 1.) or skill-style key sections
    if grep -q "## 1\." "$CONTEXT_FILE" 2>/dev/null; then
        log_pass "Core structure sections present"
    elif grep -q "Meta-Protocol Principles" "$CONTEXT_FILE" 2>/dev/null \
         && grep -q "Discovered Constraints\|Operating Principles" "$CONTEXT_FILE" 2>/dev/null \
         && grep -q "Change History" "$CONTEXT_FILE" 2>/dev/null; then
        log_pass "Core structure sections present"
    else
        log_warn "Core structure sections missing"
    fi
fi

# --- Check 3: Change History ---
if [[ -n "$CONTEXT_FILE" ]]; then
    if grep -q "Change History" "$CONTEXT_FILE" 2>/dev/null; then
        log_pass "Change History section found"
    else
        log_warn "Change History section missing"
    fi
fi

# Check 4: Link validation with specific reporting
echo_progress "Checking documentation links..."
HAS_BROKEN_LINKS=false

# Function to convert heading to GitHub-style anchor
heading_to_anchor() {
    # GitHub anchor: lowercase, remove non-alnum except spaces/dashes/underscores, spaces->dashes
    echo "$1" | \
        awk '{print tolower($0)}' | \
        sed "s/[^[:alnum:] _-]//g" | \
        tr ' ' '-' | sed 's/--*/-/g' | sed 's/^-//' | sed 's/-$//'
}

# Check links in all markdown files
while IFS= read -r -d '' file; do
    [[ -f "$file" ]] || continue

    # Find relative links using grep for better extraction
    while IFS= read -r link_match; do
        # Extract link path from [text](path) pattern
        link_path="${link_match#*](}"
        link_path="${link_path%%)*}"

        # Skip external links
        [[ "$link_path" == http* ]] && continue
        [[ "$link_path" == mailto* ]] && continue

        # Determine target file and anchor
        if [[ "$link_path" == \#* ]]; then
            # Anchor-only link - check in same file
            target_file="$file"
            anchor="${link_path#\#}"
        else
            # File link, possibly with anchor
            link_file="${link_path%%#*}"
            anchor="${link_path#*#}"
            [[ "$anchor" == "$link_path" ]] && anchor=""

            # Resolve relative path
            if [[ "$link_file" == /* ]]; then
                target_file="$PROJECT_ROOT${link_file}"
            else
                target_file="$(dirname "$file")/$link_file"
            fi

            # Check if target file exists
            if [[ ! -e "$target_file" ]]; then
                line_num=$(grep -nF "$link_path" "$file" 2>/dev/null | head -1 | cut -d: -f1)
                log_fail "Broken link: $link_path in $file:${line_num:-?}"
                HAS_BROKEN_LINKS=true
                continue
            fi
        fi

        # Validate anchor if present
        if [[ -n "$anchor" && -f "$target_file" ]]; then
            # GitHub line reference: #L10 or #L10-L20
            if [[ "$anchor" =~ ^L([0-9]+)(-L([0-9]+))?$ ]]; then
                start_line="${BASH_REMATCH[1]}"
                end_line="${BASH_REMATCH[3]:-$start_line}"
                total_lines=$(wc -l < "$target_file")
                if [[ "$end_line" -gt "$total_lines" ]]; then
                    line_num=$(grep -nF "#$anchor" "$file" 2>/dev/null | head -1 | cut -d: -f1)
                    log_fail "Line ref out of range: #$anchor (file has $total_lines lines) in $(basename "$target_file") (from $file:${line_num:-?})"
                    HAS_BROKEN_LINKS=true
                fi
            else
                # Heading anchor
                anchor_found=false
                while IFS= read -r heading; do
                    heading_text="${heading#*# }"
                    heading_anchor=$(heading_to_anchor "$heading_text")
                    if [[ "$heading_anchor" == "$anchor" ]]; then
                        anchor_found=true
                        break
                    fi
                done < <(grep -E '^#{1,6} ' "$target_file" 2>/dev/null)

                if [[ "$anchor_found" == "false" ]]; then
                    line_num=$(grep -nF "#$anchor" "$file" 2>/dev/null | head -1 | cut -d: -f1)
                    if [[ "$target_file" == "$file" ]]; then
                        log_fail "Broken anchor: #$anchor in $file:${line_num:-?}"
                    else
                        log_fail "Broken anchor: #$anchor in $(basename "$target_file") (from $file:${line_num:-?})"
                    fi
                    HAS_BROKEN_LINKS=true
                fi
            fi
        fi
    done < <(awk '/^```/{f=!f; next} !f' "$file" | grep -oE '\[[^]]*\]\([^)]+\)' 2>/dev/null)
done < <(
    find "$PROJECT_ROOT" \
        \( \
            -name "node_modules" -o \
            -name "target" -o \
            -name "build" -o \
            -name "dist" -o \
            -name "vendor" -o \
            -name "obj" -o \
            -name "out" -o \
            -name "bin" -o \
            -name "bower_components" -o \
            -name "site-packages" -o \
            -name "coverage" -o \
            -name "Pods" -o \
            -name ".git" -o \
            -name ".cache" -o \
            -name ".github" -o \
            -name ".idea" -o \
            -name ".next" -o \
            -name ".pytest_cache" -o \
            -name ".tox" -o \
            -name ".venv" -o \
            -name ".vscode" -o \
            -name "venv" -o \
            -name "temp" -o \
            -name "tmp" -o \
            -path "*/docs/_build" \
        \) -prune -o -type f -name "*.md" -print0
)

if [[ "$HAS_BROKEN_LINKS" == "false" ]]; then
    log_pass "Documentation links validated"
fi

# --- Check 5: Meta-Protocol Principles ---
if [[ -n "$CONTEXT_FILE" ]]; then
    if grep -q "Meta-Protocol Principles" "$CONTEXT_FILE" 2>/dev/null; then
        log_pass "Meta-Protocol Principles found"
    else
        log_warn "Meta-Protocol Principles missing"
    fi
fi

# --- Check 6: Bloat Analysis (replaces hardcoded line limit) ---
if [[ -n "$CONTEXT_FILE" && -f "$CONTEXT_FILE" ]]; then
    TOTAL_LINES=$(wc -l < "$CONTEXT_FILE")

    if [[ $TOTAL_LINES -lt 10 ]]; then
        echo_progress "Analyzing index file health..."
        log_info "Index metrics: ${TOTAL_LINES} lines (too small for bloat analysis)"
    else
    echo_progress "Analyzing index file health..."

    # Count structural elements
    HEADING_COUNT=$(grep -cE '^#{1,6} ' "$CONTEXT_FILE" || true)
    LIST_ITEM_COUNT=$(grep -cE '^\s*[-*] ' "$CONTEXT_FILE" || true)
    BLANK_LINE_COUNT=$(grep -cE '^\s*$' "$CONTEXT_FILE" || true)
    STRUCTURAL_ELEMENTS=$((HEADING_COUNT + LIST_ITEM_COUNT))

    # Information density: ratio of structural elements to content lines
    CONTENT_LINES=$((TOTAL_LINES - BLANK_LINE_COUNT))
    if [[ $CONTENT_LINES -gt 0 ]]; then
        # Density as percentage (structural / content * 100)
        DENSITY=$((STRUCTURAL_ELEMENTS * 100 / CONTENT_LINES))
    else
        DENSITY=0
    fi

    # Section size analysis: detect disproportionately large sections
    BLOAT_SECTIONS=()
    SECTION_SIZES=()
    SECTION_NAMES=()
    prev_line=0
    prev_name=""

    while IFS= read -r line; do
        line_num="${line%%:*}"
        heading_text="${line#*:}"
        heading_text="${heading_text#\#\# }"

        if [[ $prev_line -gt 0 ]]; then
            size=$((line_num - prev_line))
            SECTION_SIZES+=("$size")
            SECTION_NAMES+=("$prev_name")
        fi
        prev_line=$line_num
        prev_name="$heading_text"
    done < <(grep -nE '^## ' "$CONTEXT_FILE" 2>/dev/null)

    # Account for last section
    if [[ $prev_line -gt 0 ]]; then
        size=$((TOTAL_LINES - prev_line))
        SECTION_SIZES+=("$size")
        SECTION_NAMES+=("$prev_name")
    fi

    # Calculate average section size and find outliers (>2x average)
    if [[ ${#SECTION_SIZES[@]} -gt 0 ]]; then
        TOTAL_SECTION_LINES=0
        for s in "${SECTION_SIZES[@]}"; do
            TOTAL_SECTION_LINES=$((TOTAL_SECTION_LINES + s))
        done
        AVG_SIZE=$((TOTAL_SECTION_LINES / ${#SECTION_SIZES[@]}))

        for i in "${!SECTION_SIZES[@]}"; do
            if [[ ${SECTION_SIZES[$i]} -gt $((AVG_SIZE * 2)) && ${SECTION_SIZES[$i]} -gt 20 ]]; then
                BLOAT_SECTIONS+=("${SECTION_NAMES[$i]} (${SECTION_SIZES[$i]} lines, avg ${AVG_SIZE})")
            fi
        done
    fi

    # Change History entry count
    CH_ENTRIES=$(grep -cE '^\s*-\s*`\[[0-9]{4}-[0-9]{2}-[0-9]{2}\]`' "$CONTEXT_FILE" || true)

    # Report metrics
    log_info "Index metrics: ${TOTAL_LINES} lines, ${HEADING_COUNT} headings, density ${DENSITY}%"

    # Bloat signals (multiple heuristics instead of one hardcoded limit)
    BLOAT_SIGNALS=0

    # Signal 1: Low information density (<40% = verbose prose, likely bloated)
    if [[ $DENSITY -lt 40 ]]; then
        log_warn "Low information density (${DENSITY}%): index may contain verbose prose"
        BLOAT_SIGNALS=$((BLOAT_SIGNALS + 1))
    fi

    # Signal 2: Disproportionate sections
    if [[ ${#BLOAT_SECTIONS[@]} -gt 0 ]]; then
        for section in "${BLOAT_SECTIONS[@]}"; do
            log_warn "Disproportionate section: $section"
        done
        BLOAT_SIGNALS=$((BLOAT_SIGNALS + ${#BLOAT_SECTIONS[@]}))
    fi

    # Signal 3: Change History overflow (>5 entries)
    if [[ $CH_ENTRIES -gt 5 ]]; then
        log_warn "Change History has ${CH_ENTRIES} entries (max 5) — rotation needed"
        BLOAT_SIGNALS=$((BLOAT_SIGNALS + 1))
    fi

    # Signal 4: Extreme file size (adaptive: >15 lines per heading = sparse structure)
    if [[ $HEADING_COUNT -gt 0 ]]; then
        LINES_PER_HEADING=$((TOTAL_LINES / HEADING_COUNT))
        if [[ $LINES_PER_HEADING -gt 15 ]]; then
            log_warn "Sparse structure (${LINES_PER_HEADING} lines/heading): consider splitting or consolidating"
            BLOAT_SIGNALS=$((BLOAT_SIGNALS + 1))
        fi
    fi

    # Overall bloat verdict
    if [[ $BLOAT_SIGNALS -eq 0 ]]; then
        log_pass "Index file health: no bloat signals"
    elif [[ $BLOAT_SIGNALS -le 2 ]]; then
        log_warn "Index file health: ${BLOAT_SIGNALS} bloat signal(s) — consolidation recommended"
    else
        log_fail "Index file health: ${BLOAT_SIGNALS} bloat signals — garbage collection needed"
    fi
    fi # end bloat analysis (>10 lines guard)
fi

# --- Check 7: No LaTeX in markdown (GitHub doesn't render it) ---
echo_progress "Checking for LaTeX syntax..."
HAS_LATEX=false
# LaTeX-specific commands that wouldn't appear in normal markdown or shell
LATEX_COMMANDS='\\frac|\\sum|\\prod|\\int|\\rightarrow|\\leftarrow|\\Rightarrow|\\Leftarrow|\\alpha|\\beta|\\gamma|\\delta|\\epsilon|\\theta|\\lambda|\\sigma|\\omega|\\infty|\\partial|\\nabla|\\cdot|\\times|\\sqrt|\\neq|\\leq|\\geq|\\approx|\\equiv|\\begin\{|\\end\{|\\mathbb|\\mathrm|\\textbf'
while IFS= read -r -d '' file; do
    [[ -f "$file" ]] || continue
    # Exclude code blocks via awk, then inline code via grep -v, then check for LaTeX patterns
    # Only match: LaTeX commands OR $...$ containing LaTeX commands (not shell vars like $HOME)
    content=$(awk '/^```/{f=!f; next} !f' "$file" | grep -v '`[^`]*`' 2>/dev/null)
    if echo "$content" | grep -qE "($LATEX_COMMANDS)" 2>/dev/null; then
        matches=$(echo "$content" | grep -oE "(\\\\[a-zA-Z]+\{|\\\\[a-zA-Z]+)" 2>/dev/null | grep -vE '\\\\(n|t|r|s|w|d|b|0|1|2|3)$' | head -3 | tr '\n' ', ' | sed 's/,$//')
        [[ -n "$matches" ]] && log_fail "LaTeX syntax in $(basename "$file"): $matches" && HAS_LATEX=true
    fi
done < <(find "$PROJECT_ROOT/docs" -type f -name "*.md" -print0 2>/dev/null)

if [[ "$HAS_LATEX" == "false" ]]; then
    log_pass "No LaTeX syntax (GitHub compatible)"
fi

# --- Check 8: Recent activity (freshness) ---
if [[ -n "$CONTEXT_FILE" && -f "$CONTEXT_FILE" ]]; then
    AGE_DAYS=$(( ($(date +%s) - $(stat -c %Y "$CONTEXT_FILE" 2>/dev/null || stat -f %m "$CONTEXT_FILE" 2>/dev/null || echo "0")) / 86400 ))
    if [[ $AGE_DAYS -lt 30 ]]; then
        log_pass "Context is fresh ($AGE_DAYS days old)"
    else
        log_warn "Context is stale ($AGE_DAYS days old)"
    fi
fi

# --- Check 9: Documentation directory exists ---
if [[ -d "$PROJECT_ROOT/docs" ]]; then
    log_pass "Documentation directory exists"
else
    log_warn "Documentation directory missing"
fi

# --- Check 10: Docs index coverage (orphans/phantoms) ---
DOCS_INDEX="$PROJECT_ROOT/docs/README.md"
if [[ -d "$PROJECT_ROOT/docs" && -f "$DOCS_INDEX" ]]; then
    ORPHAN_COUNT=0
    PHANTOM_COUNT=0

    # Find all .md files in /docs except README.md
    while IFS= read -r -d '' doc_file; do
        # GNU realpath --relative-to is unavailable on some macOS setups.
        # Since doc_file is already under $PROJECT_ROOT/docs, prefix strip is enough.
        doc_basename="${doc_file#$PROJECT_ROOT/docs/}"
        if ! grep -qF "$doc_basename" "$DOCS_INDEX" 2>/dev/null; then
            log_warn "Orphaned doc: docs/$doc_basename (not in docs/README.md)"
            ORPHAN_COUNT=$((ORPHAN_COUNT + 1))
        fi
    done < <(find "$PROJECT_ROOT/docs" -type f -name "*.md" ! -name "README.md" -print0)

    # Check all links in docs/README.md point to existing files
    while IFS= read -r link; do
        link_path="${link#./}"
        if [[ ! -f "$PROJECT_ROOT/docs/$link_path" ]]; then
            log_warn "Phantom link in docs/README.md: $link"
            PHANTOM_COUNT=$((PHANTOM_COUNT + 1))
        fi
    done < <(grep -oE '\]\(\./[^)]+\.md' "$DOCS_INDEX" 2>/dev/null | sed 's/^](.\///')

    if [[ $ORPHAN_COUNT -eq 0 && $PHANTOM_COUNT -eq 0 ]]; then
        log_pass "Docs index coverage: 0 orphans, 0 phantoms"
    fi
fi

# Summary
if [[ "$OUTPUT_JSON" == "true" ]]; then
    # Build JSON output
    echo "{"
    echo "  \"passed\": $(( ERRORS == 0 ? 1 : 0 )),"
    echo "  \"errors\": $ERRORS,"
    echo "  \"warnings\": $WARNINGS,"
    echo "  \"items\": ["
    for i in "${!JSON_ITEMS[@]}"; do
        if [[ $i -lt $((${#JSON_ITEMS[@]} - 1)) ]]; then
            echo "    ${JSON_ITEMS[$i]},"
        else
            echo "    ${JSON_ITEMS[$i]}"
        fi
    done
    echo "  ]"
    echo "}"
else
    echo
    echo "<VALIDATION SUMMARY>"
    echo "Warnings: $WARNINGS"
    echo "Errors: $ERRORS"
    echo

    if [[ $ERRORS -eq 0 ]]; then
        echo -e "${GREEN}✓ Context validation PASSED${NC}"
        echo "Ready for Task Completion Protocol"
    else
        echo -e "${RED}✗ Context validation FAILED${NC}"
        echo "Manual intervention required"
    fi
fi

exit $(( ERRORS > 0 ? 1 : 0 ))
